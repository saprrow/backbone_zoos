{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 225, 1024])\n"
     ]
    }
   ],
   "source": [
    "img = torch.randn(12,3,240,240)\n",
    "dim = 1024\n",
    "patch_size = 16\n",
    "patch_dim = 3 * patch_size ** 2\n",
    "nums_patch = (240 // patch_size) ** 2\n",
    "patch_to_embedding = nn.Linear(patch_dim, dim)\n",
    "\n",
    "p = patch_size\n",
    "x = rearrange(img, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = p, p2 = p) # (12,3,240,240) -> (12, 15*15, 16*16*3)\n",
    "x = patch_to_embedding(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 226, 1024])\n"
     ]
    }
   ],
   "source": [
    "cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "cls_token = repeat(cls_token, '() n d -> b n d', b = 12)\n",
    "x = torch.cat((cls_token, x), dim=1)\n",
    "pos_embedding = nn.Parameter(torch.randn(12,nums_patch + 1, dim))\n",
    "x += pos_embedding[:,:nums_patch + 1]\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_qkv = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
